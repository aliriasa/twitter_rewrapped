{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Interests Model from Reddit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "from keras.layers import Input, Lambda, Dense, LSTM\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv(\"data/ml_reddit_data_final.csv\").drop(columns = [\"Unnamed: 0\"])\n",
    "\n",
    "# separate between training and testing data\n",
    "X = df[[\"text\"]]\n",
    "y = df[\"category\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.01, random_state=42)\n",
    "\n",
    "train_text = X_train[\"text\"].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "test_text = X_test[\"text\"].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "train_label = np.asarray(pd.get_dummies(y_train), dtype = np.int8)\n",
    "test_label = np.asarray(pd.get_dummies(y_test), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)))\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(UniversalEmbedding,\n",
    "\toutput_shape=(512,))(input_text)\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "pred = Dense(23, activation='sigmoid')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "\toptimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toni/opt/anaconda3/envs/my-env/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604/1604 [==============================] - 33s 16ms/step - loss: 0.8813 - accuracy: 0.7607 - val_loss: 0.6936 - val_accuracy: 0.7881\n",
      "Epoch 2/10\n",
      "1604/1604 [==============================] - 26s 16ms/step - loss: 0.6070 - accuracy: 0.8169 - val_loss: 0.6859 - val_accuracy: 0.8035\n",
      "Epoch 3/10\n",
      "1604/1604 [==============================] - 25s 15ms/step - loss: 0.5741 - accuracy: 0.8256 - val_loss: 0.6777 - val_accuracy: 0.8054\n",
      "Epoch 4/10\n",
      "1604/1604 [==============================] - 25s 15ms/step - loss: 0.5481 - accuracy: 0.8309 - val_loss: 0.6828 - val_accuracy: 0.7996\n",
      "Epoch 5/10\n",
      "1604/1604 [==============================] - 26s 16ms/step - loss: 0.5238 - accuracy: 0.8391 - val_loss: 0.6730 - val_accuracy: 0.8054\n",
      "Epoch 6/10\n",
      "1604/1604 [==============================] - 27s 17ms/step - loss: 0.4998 - accuracy: 0.8448 - val_loss: 0.6720 - val_accuracy: 0.8054\n",
      "Epoch 7/10\n",
      "1604/1604 [==============================] - 25s 16ms/step - loss: 0.4746 - accuracy: 0.8525 - val_loss: 0.7045 - val_accuracy: 0.8015\n",
      "Epoch 8/10\n",
      "1604/1604 [==============================] - 26s 16ms/step - loss: 0.4505 - accuracy: 0.8593 - val_loss: 0.6982 - val_accuracy: 0.8073\n",
      "Epoch 9/10\n",
      "1604/1604 [==============================] - 27s 17ms/step - loss: 0.4247 - accuracy: 0.8683 - val_loss: 0.6875 - val_accuracy: 0.8112\n",
      "Epoch 10/10\n",
      "1604/1604 [==============================] - 27s 17ms/step - loss: 0.3986 - accuracy: 0.8750 - val_loss: 0.7005 - val_accuracy: 0.8092\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=10,\n",
    "            batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/Users/toni/Documents/my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "956a6dba213187050bdc9c018434d3e159d77ae3e1feff45a99217d3fbe961a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
